\documentclass{proposal}

\usepackage{times}  
\usepackage{hyperref}
\usepackage{titlesec}

\hypersetup{pdfstartview=FitH,pdfpagelayout=SinglePage}

\setlength\paperheight {11in}
\setlength\paperwidth {8.5in}
\setlength{\textwidth}{7in}
\setlength{\textheight}{9.25in}
\setlength{\oddsidemargin}{-.25in}
\setlength{\evensidemargin}{-.25in}

\begin{document}

% \conferenceinfo{HotNets 2022} {}
% \CopyrightYear{2022}
% \crdata{X}
% \date{}

\title{CS395T Project Proposal: Using Fine-grained Metrics to Scale Microservices
}

\author{Rahul Menon, Leo Orshansky, Esther Yoon}

\maketitle

%%%%%%%%%%%%%  ABSTRACT GOES HERE %%%%%%%%%%%%%%
\begin{abstract}
\end{abstract}

\section{Project Idea}
% Describe the project and how it relates to the course
% Prior work and how it falls short, novelty of our approach
There is a trend towards the use of single-purpose microservices over monolithic services. Microservices are structures in the form of a DAG of container services and are divided among different machines.

Resource management is a key challenges when working with distibuted microservices. Meeting service level objectives (SLO) without overprovisioning resources is critical for performance guarantees and resource management costs. However, it can be difficult to identify where performance issues originate from within complex microservice graphs.

Typically there are two forms of scaling used for resource management of microservices. Vertical scaling is a fine-grained scaling technique that modifies resource limits, such CPU usage and I/O bandwidth usage. Horizontal scaling is a more coarse-grained approach that adjusts the number of replicas of a microservice. Oftentimes, a global controller is used to perform both types of scaling.

There are many prior approaches that leverage horizontal or vertical scaling to address microservice resource management.

Sinan is a vertical scaling approach that uses an ML model to predict the performance of per-tier resource allocations on end-to-end performance and scale resource limits accordingly. Another vertical scaler is AutoThrottle, which uses a combination of an application-level controller that uses online RL to set performance targets and per-microservice controllers and per-microservice controllers to perform fine-grained CPU scaling with local metrics. FIRM is a horizontal scaler which identifies bottleneck services using reinforcement learning. 

These prior solutions use metrics like local or end-to-end latency and resource utilization. However, another informative metric for per-microservice performance is the request arrival rates and request processing (depature) rates of each microservice. If these request rates were known at any given time, we could understand the real-time latencies incurred by individual microservices. With this latency knowledge, these \textit{queue-length based} solutions can easily identify bottlenecks that need to be scaled up. Powerchief is one such queue-length based method, however, it requires application modification to record request rate information.

Modifying application code is an undesirable quality, yet is simpler than implementing request rate collection transparently. For our project, we propose to use service meshes to transparently capture queueing statistics. A service mesh acts as an infrastructure layer between microservices, providing sidecar containers that act as a proxies for each microservice. The sidecar can then capture request arrival and departure rates and transfer them to a global controller to perform scaling.

% Challenges/novelty:
Our approach requires significant instrumentation to support transparent request rate collection. In addition to this challenge, we will have to understand how to manage the communication overhead between sidecars and the centralized controller. For example, higher frequencies of communication will lead to more fine-grained information for the controller to act on, but will incur higher communication overheads.
Other challenges to this approach include accounting for replicated microservice startup time, evaluating how local scaling policies impact end-to-end performance, and examining how request arrival and departure rates may be impacted by dependencies among microservices.

\section{Implementation Plan}
% What work must be done, and how it will be divided amonst us
% 75%, 100% and 125% goals
We have decided a logical division of this project's goals into a temporal timeline, as well as a subdivision of certain tasks into parallelizable parts to more effectively utilize our group of three. Here is said timeline:
\begin{enumerate}
    \item Initial steps and framework creation
    \begin{itemize}
        \item Setup of container services: mostly will involve writing scripts to handle horizontal scaling yaml configs and kubernetes (Esther)
        \item Sidecar/service mesh setup: general setup/scripting and implementation of request/response rate collection through the sidecar (Leo)
        \item Global controller setup: implement global knob tuning through the controller (scaling of the \# of service instances and resource limits) (Rahul)
    \end{itemize}
\end{enumerate}
\section{Resources}
% Resources we'll be using
\subsection{CloudLab}
We will be utilizing the class's CloudLab project to allocate a testing cluster for our project. This resource will become necessary for our project's success for a few reasons:
\begin{itemize}
    \item A collaborative testing environment which each of us can $\tt ssh$ into creates a standardized testing environment for each group member to work in, and removes the overhead of setting up and debugging tests on the disparate environments of our personal machines.
    \item The CloudLab cluster comes with an abundance of compute and memory resources, which will come in handy to be able to simulate a workload of realistic size on our test microservice mesh.
    \item In order to truly benchmark our auto-scaler solution, we will need more a single-machine simulation of a sample workload on the modified microservice mesh. This is due to the limited ability of a personal machine (with, say, 8 cores) to accurately model the effect of a networked and distributed microservice architecture. We might encounter false positive and false negatives in tuning the global scaling controller if we do so on a single-machine setup instead of the more accurate model of a multi-machine cloud.
\end{itemize}
Using CloudLab we will create a virtual cloud with enough machines to model many different possible microservice mesh layouts (assignments of microservices to physical/virtual machines), and this way be able to produce accurate benchmarks in the process of developing our scaler.

\section{Outcomes}
% Final evaluation plan and experiments to run
% Questions to be answered
% Impact if successful 

\bibliographystyle{abbrv} 
\begin{small}
\bibliography{proposal}
\end{small}

\end{document}

